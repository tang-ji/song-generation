{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mellotron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDx9JAJzkCYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c69311a-1270-4e59-e9c6-db2cc149041f"
      },
      "source": [
        "%cd drive/My\\ Drive/mellotron/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/mellotron\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_kxCY1vuLQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2333a33-430f-4a09-cddd-dcd37707db18"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 36kB/s \n",
            "\u001b[?25hCollecting inflect==0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/15/2d176749884cbeda0c92e0d09e1303ff53a973eb3c6bb2136803b9d962c9/inflect-0.2.5-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
            "\u001b[?25hCollecting tensorboardX==1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/95/b5eb020dcda7568cafd9a035f61bffa38570995a2a7d024283513a230406/tensorboardX-1.1-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[?25hCollecting Unidecode==1.0.22\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/ef/67085e30e8bbcdd76e2f0a4ad8151c13a2c5bce77c85f8cad6e1f16fb141/Unidecode-1.0.22-py2.py3-none-any.whl (235kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 55.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (7.0.0)\n",
            "Collecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 51.2MB/s \n",
            "\u001b[?25hCollecting jamo==0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/cc/49812faae67f9a24be6ddaf58a2cf7e8c3cbfcf5b762d9414f7103d2ea2c/jamo-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: music21 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (5.5.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (0.34.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (1.31.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->-r requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2->-r requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2->-r requirements.txt (line 1)) (49.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2->-r requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2->-r requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2->-r requirements.txt (line 1)) (3.1.0)\n",
            "Building wheels for collected packages: nltk, gast\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449904 sha256=1ffa24d635d5e77b783859d24aeada3a115fd01f0348ddaa9bfa97209d267016\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=f674b3f145b5e9ed4ead5fa11033a0b4edcd2ce99b81e34dd48365070e0795ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built nltk gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, keras-applications, tensorflow, inflect, tensorboardX, Unidecode, nltk, jamo\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "  Found existing installation: inflect 2.1.0\n",
            "    Uninstalling inflect-2.1.0:\n",
            "      Successfully uninstalled inflect-2.1.0\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed Unidecode-1.0.22 gast-0.2.2 inflect-0.2.5 jamo-0.4.1 keras-applications-1.0.8 nltk-3.4.5 tensorboard-1.15.0 tensorboardX-1.1 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcr06n-5uO2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "import sys\n",
        "sys.path.append('waveglow/')\n",
        "\n",
        "from itertools import cycle\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.io.wavfile import write\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import torch\n",
        "\n",
        "from hparams import create_hparams\n",
        "from model import Tacotron2, load_model\n",
        "from waveglow.denoiser import Denoiser\n",
        "from layers import TacotronSTFT\n",
        "from data_utils import TextMelLoader, TextMelCollate\n",
        "from text import cmudict, text_to_sequence\n",
        "from mellotron_utils import get_data_from_musicxml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewkM_V36uvEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def panner(signal, angle):\n",
        "    angle = np.radians(angle)\n",
        "    left = np.sqrt(2)/2.0 * (np.cos(angle) - np.sin(angle)) * signal\n",
        "    right = np.sqrt(2)/2.0 * (np.cos(angle) + np.sin(angle)) * signal\n",
        "    return np.dstack((left, right))[0]\n",
        "\n",
        "\n",
        "def plot_mel_f0_alignment(mel_source, mel_outputs_postnet, f0s, alignments, figsize=(16, 16)):\n",
        "    fig, axes = plt.subplots(4, 1, figsize=figsize)\n",
        "    axes = axes.flatten()\n",
        "    axes[0].imshow(mel_source, aspect='auto', origin='bottom', interpolation='none')\n",
        "    axes[1].imshow(mel_outputs_postnet, aspect='auto', origin='bottom', interpolation='none')\n",
        "    axes[2].scatter(range(len(f0s)), f0s, alpha=0.5, color='red', marker='.', s=1)\n",
        "    axes[2].set_xlim(0, len(f0s))\n",
        "    axes[3].imshow(alignments, aspect='auto', origin='bottom', interpolation='none')\n",
        "    axes[0].set_title(\"Source Mel\")\n",
        "    axes[1].set_title(\"Predicted Mel\")\n",
        "    axes[2].set_title(\"Source pitch contour\")\n",
        "    axes[3].set_title(\"Source rhythm\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "def load_mel(path):\n",
        "    audio, sampling_rate = librosa.core.load(path, sr=hparams.sampling_rate)\n",
        "    audio = torch.from_numpy(audio)\n",
        "    if sampling_rate != hparams.sampling_rate:\n",
        "        raise ValueError(\"{} SR doesn't match target {} SR\".format(\n",
        "            sampling_rate, stft.sampling_rate))\n",
        "    audio_norm = audio.unsqueeze(0)\n",
        "    audio_norm = torch.autograd.Variable(audio_norm, requires_grad=False)\n",
        "    melspec = stft.mel_spectrogram(audio_norm)\n",
        "    melspec = melspec.cuda()\n",
        "    return melspec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-RbbQ3zvbSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "78c891cd-0613-42b0-ad4e-e5573b425d53"
      },
      "source": [
        "hparams = create_hparams()\n",
        "\n",
        "stft = TacotronSTFT(hparams.filter_length, hparams.hop_length, hparams.win_length,\n",
        "                    hparams.n_mel_channels, hparams.sampling_rate, hparams.mel_fmin,\n",
        "                    hparams.mel_fmax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxKNDKz7vkj1",
        "colab_type": "text"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLztSwsfvjNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6143142d-9a93-48ef-cf9b-ba469e97ec79"
      },
      "source": [
        "checkpoint_path = \"models/mellotron_libritts.pt\"\n",
        "mellotron = load_model(hparams).cuda().eval()\n",
        "mellotron.load_state_dict(torch.load(checkpoint_path)['state_dict'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "derg4XYdvoba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2507f7f7-3c70-4a20-bc2c-a13529915157"
      },
      "source": [
        "waveglow_path = 'models/waveglow_256channels_universal_v4.pt'\n",
        "waveglow = torch.load(waveglow_path)['model'].cuda().eval()\n",
        "denoiser = Denoiser(waveglow).cuda().eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.conv.ConvTranspose1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AuEwW-2vqoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arpabet_dict = cmudict.CMUDict('data/cmu_dictionary')\n",
        "audio_paths = 'data/examples_filelist.txt'\n",
        "dataloader = TextMelLoader(audio_paths, hparams)\n",
        "datacollate = TextMelCollate(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyUlERn9xLtW",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saZuFhHw-1bV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_idx = 0\n",
        "audio_path, text, sid = dataloader.audiopaths_and_text[file_idx]\n",
        "text_encoded = torch.LongTensor(text_to_sequence(text, hparams.text_cleaners, arpabet_dict))[None, :].cuda()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shNH7A7G3PIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0ee0dde4-61c8-4dd9-e146-8f18106e9223"
      },
      "source": [
        "print(text,\"\\n\", text_encoded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exploring the expanses of space to keep our planet safe \n",
            " torch.Size([1, 51])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nTpPlup3Nq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30087821-b8b1-4ead-ac45-404284c8e823"
      },
      "source": [
        "text = \"exploring the expanses of space to keep our Victor safe \"\n",
        "text_encoded = torch.LongTensor(text_to_sequence(text, hparams.text_cleaners, arpabet_dict))[None, :].cuda()  \n",
        "print(text_encoded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 51])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JXlWX44w-sL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "942bdd0b-9e7b-4e6a-ac46-f3250031ff94"
      },
      "source": [
        "# get audio path, encoded text, pitch contour and mel for gst\n",
        "pitch_contour = dataloader[file_idx][3][None].cuda()\n",
        "mel = load_mel(audio_path)\n",
        "print(audio_path, text)\n",
        "\n",
        "# load source data to obtain rhythm using tacotron 2 as a forced aligner\n",
        "x, y = mellotron.parse_batch(datacollate([dataloader[file_idx]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/example1.wav exploring the expanses of space to keep our Victor safe \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IApEAMmZxE7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ipd.Audio(audio_path, rate=hparams.sampling_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVsmdLUjxPlr",
        "colab_type": "text"
      },
      "source": [
        "# Define Speakers Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqL9M2fxxGzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "speaker_ids = TextMelLoader(\"filelists/libritts_train_clean_100_audiopath_text_sid_shorterthan10s_atleast5min_train_filelist.txt\", hparams).speaker_ids\n",
        "speakers = pd.read_csv('filelists/libritts_speakerinfo.txt', engine='python',header=None, comment=';', sep=' *\\| *', \n",
        "                       names=['ID', 'SEX', 'SUBSET', 'MINUTES', 'NAME'])\n",
        "speakers['MELLOTRON_ID'] = speakers['ID'].apply(lambda x: speaker_ids[x] if x in speaker_ids else -1)\n",
        "female_speakers = cycle(\n",
        "    speakers.query(\"SEX == 'F' and MINUTES > 20 and MELLOTRON_ID >= 0\")['MELLOTRON_ID'].sample(frac=1).tolist())\n",
        "male_speakers = cycle(\n",
        "    speakers.query(\"SEX == 'M' and MINUTES > 20 and MELLOTRON_ID >= 0\")['MELLOTRON_ID'].sample(frac=1).tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8bMkhaExdMT",
        "colab_type": "text"
      },
      "source": [
        "# Style Transfer (Rhythm and Pitch Contour)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUSP0mC3xUc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    # get rhythm (alignment map) using tacotron 2\n",
        "    mel_outputs, mel_outputs_postnet, gate_outputs, rhythm = mellotron.forward(x)\n",
        "    rhythm = rhythm.permute(1, 0, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7eDvCXcxfRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# speaker_id = next(female_speakers) if np.random.randint(2) else next(male_speakers)\n",
        "speaker_id = 90\n",
        "speaker_id = torch.LongTensor([speaker_id]).cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "    mel_outputs, mel_outputs_postnet, gate_outputs, _ = mellotron.inference_noattention(\n",
        "        (text_encoded, mel, speaker_id, pitch_contour, rhythm))\n",
        "\n",
        "# plot_mel_f0_alignment(x[2].data.cpu().numpy()[0],\n",
        "#                       mel_outputs_postnet.data.cpu().numpy()[0],\n",
        "#                       pitch_contour.data.cpu().numpy()[0, 0],\n",
        "#                       rhythm.data.cpu().numpy()[:, 0].T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuIygGaHxhwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    audio = denoiser(waveglow.infer(mel_outputs_postnet, sigma=0.8), 0.01)[:, 0]\n",
        "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewMLk7MF5Fd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "librosa.output.write_wav(\"coline.wav\", audio[0].data.cpu().numpy(), hparams.sampling_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSIC4Z2txokg",
        "colab_type": "text"
      },
      "source": [
        "# Singing Voice from Music Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIy5hEYkxjyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = get_data_from_musicxml('data/debussy_prelude_lyrics.musicxml', 132, convert_stress=True)\n",
        "panning = {'Soprano': [-60, -30], 'Alto': [-40, -10], 'Tenor': [30, 60], 'Bass': [10, 40]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdcGWaIhxsmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_speakers_per_part = 4\n",
        "frequency_scaling = 0.4\n",
        "n_seconds = 90\n",
        "audio_stereo = np.zeros((hparams.sampling_rate*n_seconds, 2), dtype=np.float32)\n",
        "for i, (part, v) in enumerate(data.items()):\n",
        "    rhythm = data[part]['rhythm'].cuda()\n",
        "    pitch_contour = data[part]['pitch_contour'].cuda()\n",
        "    text_encoded = data[part]['text_encoded'].cuda()\n",
        "    \n",
        "    for k in range(n_speakers_per_part):\n",
        "        pan = np.random.randint(panning[part][0], panning[part][1])\n",
        "        if any(x in part.lower() for x in ('soprano', 'alto', 'female')):\n",
        "            speaker_id = torch.LongTensor([next(female_speakers)]).cuda()\n",
        "        else:\n",
        "            speaker_id = torch.LongTensor([next(male_speakers)]).cuda()\n",
        "        print(\"{} MellotronID {} pan {}\".format(part, speaker_id.item(), pan))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            mel_outputs, mel_outputs_postnet, gate_outputs, alignments_transfer = mellotron.inference_noattention(\n",
        "                (text_encoded, mel, speaker_id, pitch_contour*frequency_scaling, rhythm))\n",
        "\n",
        "            audio = denoiser(waveglow.infer(mel_outputs_postnet, sigma=0.8), 0.01)[0, 0]\n",
        "            audio = audio.cpu().numpy()\n",
        "            audio = panner(audio, pan)\n",
        "            audio_stereo[:audio.shape[0]] += audio            \n",
        "            write(\"output/{} {}.wav\".format(part, speaker_id.item()), hparams.sampling_rate, audio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KFXIshsxuuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "audio_stereo = audio_stereo / np.max(np.abs(audio_stereo))\n",
        "write(\"output/audio_stereo.wav\", hparams.sampling_rate, audio_stereo)\n",
        "ipd.Audio([audio_stereo[:,0], audio_stereo[:,1]], rate=hparams.sampling_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4uuhMlixwYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}